{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CEBD 1260 Final Programming Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 (K-Nearest Neighbors) ###\n",
    "\n",
    "1) First task to is to classify data from a cancer diagnostic database. In this database are patients with tumors, characteristics of those tumors, and biospy results indicating whether the tumor is Malignant or Benign.\n",
    "\n",
    "\n",
    "__** About the dataset **__\n",
    "\n",
    "\n",
    "In cancer_data.txt you will find the following variables:\n",
    "\n",
    "   - radius (mean of distances from center to points on the perimeter)\n",
    "   - texture (standard deviation of gray-scale values)\n",
    "   - perimeter\n",
    "   - area\n",
    "   - smoothness (local variation in radius lengths)\n",
    "   - compactness (perimeter^2 / area - 1.0)\n",
    "   - concavity (severity of concave portions of the contour)\n",
    "   - concave_points (number of concave portions of the contour)\n",
    "   - symmetry \n",
    "   - fractal_dimension (\"coastline approximation\" - 1)\n",
    "   - cancer (0 = Benign, 1 = Malignant)  *target*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use any machine learning algorithm you wish. In your answer include a short description of your algorithm of choice and predicted category of a new patient with a tumor with the following features:\n",
    "\n",
    "   - radius: 14\n",
    "   - texture: 14\n",
    "   - perimeter: 88\n",
    "   - area: 566\n",
    "   - smoothness: 1\n",
    "   - compactness: 0.08\n",
    "   - concavity: 0.06\n",
    "   - concae points: 0.04\n",
    "   - symmetry: 0.18\n",
    "   - fractal dimension: 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Spark libraries/packages\n",
    "\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569\n",
      "radius               float64\n",
      "texture              float64\n",
      "perimeter            float64\n",
      "area                 float64\n",
      "smoothness           float64\n",
      "compactness          float64\n",
      "concavity            float64\n",
      "concave_points       float64\n",
      "symmetry             float64\n",
      "fractal_dimension    float64\n",
      "cancer               float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius</th>\n",
       "      <th>texture</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>area</th>\n",
       "      <th>smoothness</th>\n",
       "      <th>compactness</th>\n",
       "      <th>concavity</th>\n",
       "      <th>concave_points</th>\n",
       "      <th>symmetry</th>\n",
       "      <th>fractal_dimension</th>\n",
       "      <th>cancer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.1180</td>\n",
       "      <td>0.2780</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.1470</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.0787</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.6</td>\n",
       "      <td>17.8</td>\n",
       "      <td>133.0</td>\n",
       "      <td>1330.0</td>\n",
       "      <td>0.0847</td>\n",
       "      <td>0.0786</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.0702</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.0567</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.7</td>\n",
       "      <td>21.3</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.1970</td>\n",
       "      <td>0.1280</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.4</td>\n",
       "      <td>20.4</td>\n",
       "      <td>77.6</td>\n",
       "      <td>386.0</td>\n",
       "      <td>0.1420</td>\n",
       "      <td>0.2840</td>\n",
       "      <td>0.2410</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.3</td>\n",
       "      <td>14.3</td>\n",
       "      <td>135.0</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1330</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.0588</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   radius  texture  perimeter    area  smoothness  compactness  concavity  \\\n",
       "0    18.0     10.4      123.0  1000.0      0.1180       0.2780     0.3000   \n",
       "1    20.6     17.8      133.0  1330.0      0.0847       0.0786     0.0869   \n",
       "2    19.7     21.3      130.0  1200.0      0.1100       0.1600     0.1970   \n",
       "3    11.4     20.4       77.6   386.0      0.1420       0.2840     0.2410   \n",
       "4    20.3     14.3      135.0  1300.0      0.1000       0.1330     0.1980   \n",
       "\n",
       "   concave_points  symmetry  fractal_dimension  cancer  \n",
       "0          0.1470     0.242             0.0787     0.0  \n",
       "1          0.0702     0.181             0.0567     0.0  \n",
       "2          0.1280     0.207             0.0600     0.0  \n",
       "3          0.1050     0.260             0.0974     0.0  \n",
       "4          0.1040     0.181             0.0588     0.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Read training data\n",
    "df = pd.read_csv(\"Data/cancer_data.csv\")\n",
    "      \n",
    "#Get dataset information   \n",
    "print(len(df))\n",
    "print(df.dtypes)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#from sklearn.cross_validation import train_test_split (deprecated)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#set k initially\n",
    "k = 3\n",
    "\n",
    "# Split the data into train and test for:\n",
    "# 1. A training dataset that kNN to use to make predictions \n",
    "# 2. A test dataset that we can use to evaluate the accuracy of the model\n",
    "\n",
    "X_train = df.iloc[:,:10]\n",
    "ys = df['cancer']\n",
    "y_train= ys.to_frame(name='cancer')\n",
    "\n",
    "# create design matrix X and target vector y \n",
    "X = np.array(df.iloc[:,:10].values) \n",
    "y = np.array(df['cancer'])  #separate our data fom actual targets themselves\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "print(type(X))\n",
    "print(type(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy classification core is:  0.898936170213\n"
     ]
    }
   ],
   "source": [
    "# loading library\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# instantiate learning model (k = 3)\n",
    "knn = KNeighborsClassifier(n_neighbors=3, weights='distance')\n",
    "\n",
    "# fitting the model\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# predict the response\n",
    "pred = knn.predict(X_test)\n",
    "\n",
    "# evaluate accuracy\n",
    "print('The accuracy classification core is: ', accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The category of the new patient is: 1.0\n"
     ]
    }
   ],
   "source": [
    "#Predict category of a new patient with a tumor with the features listed.\n",
    "\n",
    "#Predict the class label (cancer (0 = Benign, 1 = Malignant) target) to which unseen samples belong\n",
    "\n",
    "# radius: 14  texture: 14 perimeter: 88 area: 566 smoothness: 1 compactness: 0.08\n",
    "# concavity: 0.06 concae points: 0.04 symmetry: 0.18 fractal dimension: 0.05\n",
    "\n",
    "feature = [14,14,88,566,1,0.08,0.06,0.04,0.18,0.05]\n",
    "\n",
    "pred = knn.predict([feature])\n",
    "print('The category of the new patient is:', pred[0])\n",
    "#type(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predicted summary #####\n",
    "The class label for the sample data provided is 1 (class 1 = Malignant)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 (Support Vector Machine) ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code contains a 5 bugs (errors). Find and correct them all and then answer the following questions:\n",
    "\n",
    "  1. How many observations are in the training dataset?\n",
    "  2. How many features are in the training dataset?\n",
    "  3. How well did your model perform?\n",
    "\n",
    "  BONUS: Which category is Hockey? 0 or 1? Which category is baseball?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List of bug corrections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Modified statement \n",
    "from: sklearn.pipeline import pipeline \n",
    "to: from sklearn.pipeline import Pipeline\n",
    "\n",
    "(2) Modified statement\n",
    "from: sklearn_linear_model import SGDClassifier \n",
    "to: from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "(3) Changed dataset name to reflect subset data extracted: \n",
    "    twenty_train = fetch_20newsgroups(subset='test', categories=categories) to:\n",
    "    twenty_test = fetch_20newsgroups(subset='test', categories=categories)\n",
    "\n",
    "(4) Changed dataset name to subset subset data extracted:\n",
    "    twenty_test = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42) to:\n",
    "    twenty_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)\n",
    "\n",
    "(5) Modified statement:\n",
    "    text_clf.fit(twenty_train.data, twenty_test.target) to :\n",
    "    text_clf.fit(twenty_train.data, twenty_train.target) \n",
    "    \n",
    "    reason=> the parameters to the fit method are the training data and the target values of its train samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading dataset from http://people.csail.mit.edu/jrennie/20Newsgroups/20news-bydate.tar.gz (14 MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR', 'description'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "categories = [ 'rec.sport.baseball','rec.sport.hockey']\n",
    "\n",
    "twenty_test = fetch_20newsgroups(subset='test', categories=categories)\n",
    "twenty_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)\n",
    "\n",
    "#Some descriptions of the sklearn bunch dataset\n",
    "\n",
    "type(twenty_train)\n",
    "len(twenty_train) # 6 columns/attributes\n",
    "print(twenty_train.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. How many observations are in the training dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of observations are 1197\n"
     ]
    }
   ],
   "source": [
    "#1 How many observations are in the training dataset?\n",
    "\n",
    "l=len(twenty_train['data'])\n",
    "print(\"The number of observations are\", l)\n",
    "\n",
    "#for key, value in twenty_train.items() :\n",
    "#    print (key, value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. How many features are in the training dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of features is 1197\n"
     ]
    }
   ],
   "source": [
    "#2 How many features are in the training dataset?\n",
    "\n",
    "# twenty_train.data contains the features (data of raw text used for classification)\n",
    "# print(twenty_train.data)\n",
    "\n",
    "#The data \"twenty_train\" is a 2 D array with the shape (number of samples, number of features). \n",
    "#In our case, a sample of filenames of shape (1197,) - the files are loaded in data attribute\n",
    "\n",
    "l1 = len(twenty_train.data)\n",
    "l2 = len(twenty_train.filenames)\n",
    "num_features=twenty_train.filenames.shape\n",
    "\n",
    "print(\"The number of features is\", num_features[0]) #tuple: (1197,)\n",
    "\n",
    "\n",
    "#Some checking statements\n",
    "#print(\"l1=\",l1)\n",
    "#print(\"l2=\",l1)\n",
    "#print(twenty_train.target[0], twenty_train.data[0])\n",
    "#print(twenty_train.filenames[0])\n",
    "#type(twenty_train.filenames) #numpy.ndarray\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. How well did your model perform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension is  1197  arcticles, 18571 words/stems\n"
     ]
    }
   ],
   "source": [
    "#Convert a collection of text documents to a matrix of token counts\n",
    "#frequency count (and not tf-idf)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "X_train_counts.shape \n",
    "type(X_train_counts)\n",
    "\n",
    "#dimension 1197 arcticles, 18571 words/stems\n",
    "\n",
    "print(\"Dimension is \" ,X_train_counts.shape[0], \" arcticles,\", X_train_counts.shape[1], \"words/stems\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The performance of the SGDClassifier on the twenty_test data is =  0.968592964824\n",
      "\n",
      "Metrics classification report: \n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "rec.sport.baseball       0.97      0.96      0.97       397\n",
      "  rec.sport.hockey       0.97      0.97      0.97       399\n",
      "\n",
      "       avg / total       0.97      0.97      0.97       796\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use support vector machines algorithm to evaluate the performance the text classification algorithm model\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                           alpha=1e-3, random_state=42))])\n",
    "\n",
    "# Learn from the model done by passing our training set to the fit method\n",
    "text_clf.fit(twenty_train.data, twenty_train.target)  \n",
    "predicted = text_clf.predict(twenty_test.data)\n",
    "\n",
    "print('The performance of the SGDClassifier on the twenty_test data is = ', np.mean(predicted == twenty_test.target))\n",
    "\n",
    "#print(\"predicted = \",predicted)\n",
    "\n",
    "#Text summary report\n",
    "print('\\nMetrics classification report: \\n',\n",
    "      metrics.classification_report(twenty_test.target, predicted, target_names=twenty_test.target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Which category is Hockey? 0 or 1? Which category is baseball?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First ten target index list [0 1 0 1 0 1 0 1 1 1] \n",
      "\n",
      "The category name for  0  is:  rec.sport.baseball\n",
      "The category name for  1  is:  rec.sport.hockey\n"
     ]
    }
   ],
   "source": [
    "count_vect = CountVectorizer()\n",
    "train_count = count_vect.fit_transform(twenty_train.data)\n",
    "\n",
    "train_count.shape \n",
    "\n",
    "# There are 1197 arcticles, 18571 words or stems\n",
    "\n",
    "#twenty_test.target_names\n",
    "#print(twenty_train.target_names[twenty_train.target[1]])\n",
    "\n",
    "# The target attribute is the integer index of the category\n",
    "\n",
    "print(\"First ten target index list\",  twenty_train.target[:10],'\\n')\n",
    "print(\"The category name for \",twenty_train.target[0], \" is: \", twenty_train.target_names[twenty_train.target[0]])\n",
    "print(\"The category name for \",twenty_train.target[1], \" is: \", twenty_train.target_names[twenty_train.target[1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hockey belongs to : 1  ( rec.sport.hockey )\n"
     ]
    }
   ],
   "source": [
    "# Which category is Hockey? 0 or 1? Which category is baseball?\n",
    "\n",
    "predict_h = text_clf.predict([\"Hockey\"])\n",
    "\n",
    "print(\"Hockey belongs to :\", predict_h[0],\" (\", twenty_train.target_names[predict_h[0]],\")\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseball belongs to : 0  ( rec.sport.baseball )\n"
     ]
    }
   ],
   "source": [
    "#Which category is baseball?\n",
    "predict_b  = text_clf.predict([\"Baseball\"])\n",
    "print(\"Baseball belongs to :\", predict_b[0],\" (\", twenty_train.target_names[predict_b[0]],\")\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rec.sport.baseball', 'rec.sport.hockey']\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(list(twenty_train.target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
